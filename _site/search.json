[
  {
    "objectID": "photo.html",
    "href": "photo.html",
    "title": "Photo gallery",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Facebook\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Github\n  \n\n  \n  \nAshlynn Lu is a statistics and data science postgraduate student.\nShe is currently studying at Imperial College London.\nWhen not innovating on data analysis, Ashlynn enjoys spending time gaming, playing guitar and taking pictures.\n\n\nImperial College London | London, UK Statistics (Data Science) (MSc) | Sept 2023 – Sep 2024 (ongoing)\nThe University of Edinburgh | Edinburgh, UK Mathematics and Statistics (BSc Hons) | Sept 2019 – May 2023\n\n\n\nExploration into the subjective interpretation of statistical information via the use of visual displays of data | R | Sept 2022 – Mar 2023\nInvestigating the impact of age and sex on guillemot survival probabilities | R | July 2022 – Aug 2022\nInvestigating the pattern of the stop and search in City of London | R | Oct 2019 – Nov 2019\n\n\n\nThe Lawley Prize | 2023 The University of Edinburgh | Edinburgh, UK\nThe College Vacation Scholarship | 2022 The University of Edinburgh | Edinburgh, UK\n\n\n\nProgramming languages & Analytical software: Python, R, SQL, Xpress, STATA, SPSS, Microsoft Office: Excel, PowerPoint, etc.\nLanguages: Fluent English, native-level Chinese, fluent Japanese\nOther skills: Video editing, illustration, new media operation"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "",
    "text": "Imperial College London | London, UK Statistics (Data Science) (MSc) | Sept 2023 – Sep 2024 (ongoing)\nThe University of Edinburgh | Edinburgh, UK Mathematics and Statistics (BSc Hons) | Sept 2019 – May 2023"
  },
  {
    "objectID": "about.html#projects",
    "href": "about.html#projects",
    "title": "About",
    "section": "",
    "text": "Exploration into the subjective interpretation of statistical information via the use of visual displays of data | R | Sept 2022 – Mar 2023\nInvestigating the impact of age and sex on guillemot survival probabilities | R | July 2022 – Aug 2022\nInvestigating the pattern of the stop and search in City of London | R | Oct 2019 – Nov 2019"
  },
  {
    "objectID": "about.html#awards",
    "href": "about.html#awards",
    "title": "About",
    "section": "",
    "text": "The Lawley Prize | 2023 The University of Edinburgh | Edinburgh, UK\nThe College Vacation Scholarship | 2022 The University of Edinburgh | Edinburgh, UK"
  },
  {
    "objectID": "about.html#skills",
    "href": "about.html#skills",
    "title": "About",
    "section": "",
    "text": "Programming languages & Analytical software: Python, R, SQL, Xpress, STATA, SPSS, Microsoft Office: Excel, PowerPoint, etc.\nLanguages: Fluent English, native-level Chinese, fluent Japanese\nOther skills: Video editing, illustration, new media operation"
  },
  {
    "objectID": "posts/2024-02-21_cannabis-sales/index.html",
    "href": "posts/2024-02-21_cannabis-sales/index.html",
    "title": "Colorado Legal Cannabis Sales Report",
    "section": "",
    "text": "In Colorado, cannabis has been legal for medical use since 2000 and for recreational use since late 2012.\nThe public was expecting to finally see recreational use sales data, and hopefully, that could match the historical sales before the legalisation. Thanks to the documented sales data from the legal sellers, we can now finally have a quantitative glance into the sale of this special and controversial good.\n\nIt is not surprising to see that retail sales quickly overtake the majority of total sales and became nearly twice the medical sales in less than 5 years time. This shows a graduate market acceptance for recreational use sales, which is expected considering its past crime-related nature. Now, recreational sales are dominating the total sales and are likely to stay in this position for the foreseeable future.\n\n\nThe intention of the legalisation is to regulate and monitor the market, the active legal market proves that it has been achieved to some extent. However, another question remains, that is ‘does total legalisation bring easier access to addictive goods for the public and do more damage than credit?’. This policy stays as controversial as cannabis itself.\nCounty-level data on retail and medical cannabis sales in the state from January 2014 to January 2024 published by the Colorado Department of Revenue is used to generate the information above. The visualisations focused on the top counties which contributed the largest sales in Colorado.\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/2023-02-15_potential-flows/index.html",
    "href": "posts/2023-02-15_potential-flows/index.html",
    "title": "Complex Analysis Method for Potential Flows and the Resulting Lift",
    "section": "",
    "text": "we are going to use complex-variable methods to compute two-dimensional irrotational flows of inviscid incompressible fluids around objects. We can use complex mappings to find flows around more complicated shapes than the circular cylinder."
  },
  {
    "objectID": "posts/2023-02-15_potential-flows/index.html#singularities",
    "href": "posts/2023-02-15_potential-flows/index.html#singularities",
    "title": "Complex Analysis Method for Potential Flows and the Resulting Lift",
    "section": "Singularities",
    "text": "Singularities\nConsider a complex variable \\(\\zeta = \\xi + \\mathrm{i} \\eta\\) and the flow around a disc \\(D\\) of radius \\(c\\) centred at some \\(\\zeta_0\\) in the \\(\\zeta\\)-plane. Let \\(\\kappa\\) be the circulation, the complex potential corresponding to this is\n\\[\n    \\hat{w}(\\zeta)=-(U-\\mathrm{i} V)\\left(\\zeta-\\zeta_0\\right)-(U+\\mathrm{i} V) \\frac{c^2}{\\zeta-\\zeta_0}-\\frac{\\mathrm{i} \\kappa}{2 \\pi} \\log \\frac{\\zeta-\\zeta_0}{c}.\n\\]\nWe can use an invertible map \\(z=f(\\zeta)\\) that is analytic outside the disc and getting close to the identity as \\(|\\zeta| \\rightarrow \\infty\\) to define a complex potential in the \\(z\\)-plane by \\[\n    w(z)=\\hat{w}(\\zeta) \\quad \\text { with } \\quad z=f(\\zeta).\n\\]\nThis complex potential then describes the flow around the image of \\(D\\) by the map \\(f(\\zeta)\\). To compute the flow around realistic-looking wings, we take the map \\[\n    f(\\zeta) = \\zeta + \\frac{\\lambda^2}{\\zeta}, \\quad 0 \\leq \\lambda &lt; 1,\n\\] and \\(\\zeta_0\\) in the complex plane. We are going to examine the singularities of the inverse map \\(f^{-1}(z)\\). We say \\(z_0\\) is a singularity of \\(f\\) if \\(f\\) is not holomorphic at \\(z_0\\). Inverting and differentiating \\(f(\\zeta)\\) we get \\[\n\\zeta = f^{-1}(z) = \\frac{z \\pm \\sqrt{z^2 - 4\\lambda^2}}{2}, \\space \\text{and} \\quad \\frac{\\partial\\zeta}{\\partial z} = \\frac{1}{2} \\pm \\frac{z}{\\sqrt{z^2-4\\lambda^2}}.\n\\]\nBy definition, the derivative is not defined at \\(z = \\pm 2\\lambda\\), so \\(z = \\pm 2\\lambda\\) are square root singularities of \\(f^{-1}(z)\\), corresponding to \\(\\zeta = \\pm \\lambda\\).\nWe let \\(\\zeta_0 = - \\lambda + c e^{\\mathrm{i} \\beta}\\) for some \\(\\beta &gt; 0\\) such that \\(c\\cos{\\beta} &gt; \\lambda\\). Now we are going to identify the positions of the singularities. For \\(\\zeta = \\lambda\\), we can compute the distance from the centre \\(\\zeta_0\\) to \\(\\zeta\\) as \\[\n\\begin{align*}\n    | \\zeta_0 - \\zeta | = |-2 \\lambda + c e^{\\mathrm{i} \\beta}|\n                          &= |-2 \\lambda + c(\\cos{\\beta} + \\mathrm{i}\\sin{\\beta})| \\\\\n                          &= \\sqrt{(-2 \\lambda + c\\cos{\\beta})^2 + c^2\\sin^2{\\beta}} \\\\\n                          &= \\sqrt{4\\lambda (\\lambda - c\\cos{\\beta}) + c^2(\\cos^2{\\beta} + \\sin^2{\\beta})} \\nonumber\n                          &lt;\\sqrt{c^2} = c.\n\\end{align*}\n\\]\nSince \\(| \\zeta_0 - \\zeta |\\) is shorter than the radius of the disc \\(D\\), the singularity \\(\\zeta = \\lambda\\) is inside \\(D\\). Similarly, we get \\(| \\zeta_0 - \\zeta_1 | = |c e^{\\mathrm{i} \\beta}| = c\\) for \\(\\zeta_1 = -\\lambda\\), indicating that the singularity \\(\\zeta_1\\) is on the circle \\(\\partial D\\)."
  },
  {
    "objectID": "posts/2023-02-15_potential-flows/index.html#flow-around-wings",
    "href": "posts/2023-02-15_potential-flows/index.html#flow-around-wings",
    "title": "Complex Analysis Method for Potential Flows and the Resulting Lift",
    "section": "Flow around wings",
    "text": "Flow around wings\n\n\n\nThe resemble wings obtained by mapping \\(D\\) with \\(f\\) with parameters fixed \\(c = 1\\), \\(\\lambda = 0.9\\), and \\(\\beta = 0\\) (left), 0.3 (middle), and 0.4.\n\n\n\n\n\nThe resemble wings obtained by mapping \\(D\\) with \\(f\\) with parameters fixed \\(c = 1\\), \\(\\beta = 0.3\\), and \\(\\lambda = 0.5\\) (left), 0.2 (middle), and 0.\n\n\nAs \\(c\\) is the radius of disc \\(D\\), we may fix it as a constant. For simple calculation we take \\(c = 1\\). The resemble wings all have a smooth leading edge and a cusp at the trailing edge corresponding to \\(\\zeta =\\zeta_1\\), except the one on the bottom right. We found that a wing with larger value of \\(\\beta\\) has more curved shape. When \\(\\beta = 0\\), the wing becomes a symmetric drop shape. We can say that the degree of curvature of the wing shape depends on \\(\\beta\\). Also, it can be seen that a wing with lower \\(\\lambda\\) has rounder shape. Particularly, when \\(\\lambda = 0\\), the map becomes an identity map, hence the shape becomes a circle. Thus we may conclude that \\(\\lambda\\) control the roundness of the shape.\nWe can compute the velocity field using the derivative of the flow as \\[\n\\begin{align*}\n    u-\\mathrm{i} v=w^{\\prime}(z)&=\\hat{w}^{\\prime}(\\zeta) / f^{\\prime}(\\zeta)  \\\\\n    &=\\left(1-\\lambda^2 / \\zeta^2\\right)^{-1}\\left(-(U-\\mathrm{i} V)+(U+\\mathrm{i} V) c^2/(\\zeta-\\zeta_0)^{2}-\\mathrm{i} \\kappa /(2 \\pi (\\zeta-\\zeta_0))\\right)\\\\\n    &=\\left(1-\\lambda^2 / \\zeta^2\\right)^{-1}\\left(-|\\mathbf{U}|e^{\\mathrm{i}\\alpha}+|\\mathbf{U}|e^{-\\mathrm{i} \\alpha} c^2/(\\zeta-\\zeta_0)^{2}-\\mathrm{i} \\kappa /(2 \\pi (\\zeta-\\zeta_0))\\right),\n\\end{align*}\n\\] where \\(U + \\mathrm{i}V = |\\mathbf{U}|e^{-i\\alpha}\\) defines the angle of attack \\(\\alpha\\). The velocity field is infinite at the trailing edge corresponding to \\(\\zeta_1 = -\\lambda\\) since \\(f^{\\prime}(\\zeta_1) = 0\\), except when \\(\\hat{w}^{\\prime}(\\zeta_1) = 0\\).\nNow we are going to derive an expression for the circulation, \\(\\kappa\\), which takes a value such that the trailing edge velocity remains finite. So we need to find \\(\\kappa\\) which makes \\(\\hat{w}^{\\prime}(\\zeta_1) = 0\\). Using \\(\\zeta_1-\\zeta_0 = -\\lambda + \\lambda - ce^{i\\beta} = - ce^{i\\beta}\\), we have \\(\\hat{w}^{\\prime}(\\zeta_1) = -|\\mathbf{U}|e^{\\mathrm{i}\\alpha}+|\\mathbf{U}|e^{-\\mathrm{i}(\\alpha+2\\beta)}+\\mathrm{i} \\kappa /(2 \\pi c) e^{-\\mathrm{i}\\beta}=0\\). Solving for \\(\\kappa\\) we get \\[\n    \\kappa = (|\\mathbf{U}|e^{\\mathrm{i}(\\alpha+\\beta)} - |\\mathbf{U}|e^{-\\mathrm{i}(\\alpha+\\beta)})(2\\pi c/\\mathrm{i}) = 2|\\mathbf{U}|\\mathrm{i}\\sin{(\\alpha+\\beta)}(2\\pi c/\\mathrm{i}) = 4\\pi c|\\mathbf{U}|\\sin{(\\alpha+\\beta)}.\\nonumber\n\\]\nTherefore, if \\(\\kappa \\neq 4\\pi c|\\mathbf{U}| \\sin{(\\alpha+\\beta)}\\), we have \\(\\hat{w}^{\\prime}(\\zeta_1) \\neq 0\\), resulting a infinite velocity field at the trailing edge."
  },
  {
    "objectID": "posts/2023-02-15_potential-flows/index.html#resulting-lift",
    "href": "posts/2023-02-15_potential-flows/index.html#resulting-lift",
    "title": "Complex Analysis Method for Potential Flows and the Resulting Lift",
    "section": "Resulting lift",
    "text": "Resulting lift\nThe lift for the wing is computed as the force perpendicular to the velocity at infinity, \\(\\kappa|\\mathbf{U}|\\). Without loss of generality, we can take \\(|\\mathbf{U}| = c = 1\\), thus we get an expression for lift which is \\(4\\pi \\sin{(\\alpha+\\beta)}\\). The lift for the wing therefore depends on \\(\\alpha\\) and \\(\\beta\\).\n\n\n\nThe velocity field around some wings designed using fixed \\(c = 1\\), \\(\\lambda = 0.9\\), and different values of \\(\\alpha\\) and \\(\\beta\\). The lift for wings are shown below each plot.\n\n\nThe expression for the lift of the wing indicates that the relationship between the lift and parameters \\(\\alpha\\) and \\(\\beta\\) is a sine function.\n\n\n\nThe lift for the wing computed using different value of \\(\\alpha\\) and \\(\\beta\\).\n\n\nWe can deduce from the plot that the lift is at maximum when \\(\\alpha + \\beta = \\pi/2\\)."
  },
  {
    "objectID": "posts/2023-02-15_potential-flows/index.html#discussion",
    "href": "posts/2023-02-15_potential-flows/index.html#discussion",
    "title": "Complex Analysis Method for Potential Flows and the Resulting Lift",
    "section": "Discussion",
    "text": "Discussion\nWe explored on how the complex formulation leads to predictions for the flow around wings. The roundness and curvature of the wings are controlled by \\(\\lambda\\) and \\(\\beta\\) respectively. We conclude that the velocity field is always infinite at the trailing edge unless \\(\\kappa = 4\\pi c|\\mathbf{U}|\\sin{(\\alpha+\\beta)}\\), and the maximum lift for the wing is then reached when \\(\\alpha + \\beta = \\pi/2\\). However, for flow of real fluid, if a viscous flow past a cylinder, it will acquire a thin boundary layer adjacent to the surface of the cylinder. A trailing wake will exist in the flow behind the cylinder due to Boundary layer separation. The pressure at each point on the wake side of the cylinder will be lower than on the upstream side, resulting in a drag force in the downstream direction"
  },
  {
    "objectID": "posts/2022-08-19_guillemot-survival/index.html",
    "href": "posts/2022-08-19_guillemot-survival/index.html",
    "title": "Investigating the impact of age and sex on guillemot survival",
    "section": "",
    "text": "The project is motivated by a capture-recapture dataset from the largest colony of common guillemot in the Baltic Sea, Stora Karlsö. Data were recorded from 2009 to 2021.\nPhoto by Aron Heidström,  Baltic Seabird Project\nSeabirds inhabit marine ecosystems and they share several life history traits: high adult survival, a progressive access to reproduction at relatively old ages, a low reproductive rate and a low number of natural predators. Adult survival as well as juvenile survival, are considered important traits that influence population dynamics in seabird species. However, survival estimation can be challenging.\nIdeally, individuals would be followed from birth to death with a given study period, but this is rarely possible for wild populations. The problem arises since the observation process relating to individuals is imperfect, and hence we cannot always make a direct measurement of the state variable of interest (i.e. alive or dead). In the wild, if an individual is not observed two options are possible: (i) it is dead, or (ii) it is still alive (but it has not been observed). This problem can be addressed using the capture-mark-recapture (CMR) method.\nCMR methods use data collection protocols where observers go into the field at a series of capture events, denoted \\(t = 1, . . . , T\\). At each capture event, the observer marks the new individuals, records all observed individuals (already marked) and releases them back into the population. This leads to data corresponding to the capture history of each individual, detailing at which capture occasions they are observed or not.\nA capture history or capture-recapture takes the form of a vector of length the number of encounter occasions \\(T\\), and records the value 1 for a live encounter and 0 when an individual was not encountered. For example, an record of length \\(T=4\\) with entries (1, 1, 0, 1) means the individual was observed at \\(t = 1, 2, 4\\), while was not observed at \\(t = 3\\). This data set also contains the sex of each individual as an additional information. The main interest in this project is to estimate the main parameters, which are the recapture and the apparent survival probabilities. The survival probabilities, denoted by \\(\\phi_t\\), represent the probability of that an individual is alive at time \\(t\\) and survives until time \\(t+1\\) (for time \\(t = 1, ..., T-1\\), for all individuals). Similarly, the recapture probabilities, denoted by \\(p_t\\) represent the probability of observing an individual at time \\(t\\) (from \\(t = 2, ..., T\\) and for all individuals).\nWe use \\(p_t\\) to denote the recapture probability at occasion \\(t\\), ang \\(\\phi_t\\) to denote the apparent survival probability between occasion \\(t\\) and \\(t+1\\).\nThe primary interest in these studies is usually the estimation of survival probabilities and the associated factors (or covariates) that may influence these. Such covariates may include for example, age, environmental covariates, sex, individual heterogeneity, etc. In this project we will focus on the estimation of age and/or sex-dependent survival probabilities for this colony of common guillemots. This will involve developing statistical models to incorporate and assess the impact of age and sex on the survival estimates within a formal modelling framework in order to improve our understanding of the population which in turn may aid in their management and conservation.\nIn the next table, and for simplicity, we present a subset of the data,\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\nSex\n\n\n\n\n1\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\nM\n\n\n1\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\nF\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\nF\n\n\n1\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\nF\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\nF\n\n\n1\n0\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n1\nF\nEach row contains a capture history across 13 occasions for each individuals with the last column indicate their sex. The database contains information about 117 individuals, all of them ringed as chicks i.e. at age 1, therefore \\(T = 13\\).\nIn this study we will use the standard Cormack-Jolly-Seber (CJS) model which is considered a general framework for several number of extensions and which is conditional at initial capture (ringing time). More information about these and related models see: Serber and Schofield, 2019; McCrea and Morgan, 2015; king et al. 2010 (among many others).\nWe are going to implement CJS models in the frequentist approach, building likelihood function for each model, then use optim function to find the maximum likelihood estimate (MLE) for \\(\\boldsymbol{p}\\) and \\(\\boldsymbol{\\phi}\\) parameters."
  },
  {
    "objectID": "posts/2022-08-19_guillemot-survival/index.html#constant-model",
    "href": "posts/2022-08-19_guillemot-survival/index.html#constant-model",
    "title": "Investigating the impact of age and sex on guillemot survival",
    "section": "1. Constant Model",
    "text": "1. Constant Model\nWe start with the most basic model: model with constant \\(\\boldsymbol{p}\\) and \\(\\boldsymbol{\\phi}\\) parameters. In other words, recapture and survival probabilities are invariant with age, time and sex.\nFirstly, we need to transform the capture history into m-array format. M-array is a \\((T-1) \\times T\\) matrix with each row representing a released occasion (\\(i = 1, ..., T-1\\)), and each column representing a recapture occasion (\\(j = 2, ..., T\\)). The last column contains the number of individuals that have never been recaptured in each released occasion. For example, the \\([1, 2]\\) cell contains the number of individuals which released in occasion 1 and next recaptured in occasion 2.\nWe have defined a function marray in functions.R file to help us to transform the data. Let marr.full be the m-array of the full data set, which is shown below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nj = 2\nj = 3\nj = 4\nj = 5\nj = 6\nj = 7\nj = 8\nj = 9\nj = 10\nj = 11\nj = 12\nj = 13\nnever recaptured\n\n\n\n\ni = 1\n0\n1\n2\n1\n0\n1\n0\n1\n0\n0\n0\n0\n1\n\n\ni = 2\n0\n0\n0\n2\n1\n1\n0\n1\n0\n0\n0\n0\n1\n\n\ni = 3\n0\n0\n1\n0\n5\n4\n0\n0\n0\n0\n0\n0\n0\n\n\ni = 4\n0\n0\n0\n3\n0\n2\n1\n0\n0\n0\n0\n0\n3\n\n\ni = 5\n0\n0\n0\n0\n6\n2\n11\n4\n0\n0\n0\n0\n3\n\n\ni = 6\n0\n0\n0\n0\n0\n12\n0\n1\n0\n0\n0\n0\n0\n\n\ni = 7\n0\n0\n0\n0\n0\n0\n21\n1\n0\n0\n0\n0\n0\n\n\ni = 8\n0\n0\n0\n0\n0\n0\n0\n33\n0\n0\n0\n0\n1\n\n\ni = 9\n0\n0\n0\n0\n0\n0\n0\n0\n37\n2\n6\n1\n12\n\n\ni = 10\n0\n0\n0\n0\n0\n0\n0\n0\n0\n35\n4\n10\n17\n\n\ni = 11\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n31\n1\n26\n\n\ni = 12\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n35\n6\n\n\n\n\n\nNext we are going to form a likelihood function for the constant model.\nLet \\(\\underline{x}\\) be the capture history of the whole data where \\(x_i\\) is the capture history of individual \\(i = 1, ..., 117\\), and \\(\\boldsymbol{\\theta}\\) be the parameters used to estimate \\(p\\) and \\(\\phi\\). Since we are going to use optim to maximise the negative log likelihood function to give the MLE of the desired parameters, we need to remove the boundary of the parameters. Let \\(\\boldsymbol{\\theta}\\) be an array contains the logit transformation of the parameters \\(\\phi\\) and \\(p\\), then the boundary of \\(\\boldsymbol{\\theta}\\) is now all real numbers instead of \\((0, 1)\\).\nEach row of the m-array follows a multinomial distribution with parameters \\(N_i\\) and \\(\\underline{q}\\), then the likelihood function of the whole data is the product of multinomial distribution, i.e.\n\\[\nL(\\underline{x};\\theta) = \\prod_{i}^{T-1}Multinomial(N_i, \\underline{q})\n\\] where \\(N_i\\) represents the total number of released animals at time \\(i\\) and \\(\\underline{q} = f(\\phi, p)\\) is a matrix which represents the cell probabilities depending on \\(\\boldsymbol{\\phi}\\) and \\(\\boldsymbol{p}\\).\nNow we are going to explain how to construct \\(\\underline{q}\\).\nFirstly we need to explain how to compute the probability of a capture history. For example, if we have a capture history\n\\[\nx_i = 1 \\quad 1 \\quad 0 \\quad 1 \\quad 1\n\\]\nthe probability of this capture history is\n\\[\n\\mathbb{P}(x_i) = \\phi p \\phi (1-p) \\phi p \\phi p\n\\]\nSo each cell in matrix \\(\\underline{q}\\) represent the probability of an individual being in the corresponding cell in the m-array. As the row sum of the probabilities is 1, the last column which represent the probability of never recaptured is 1 - row sum. For example, when \\(T = 5\\), matrix \\(\\underline{q}\\) has the form shown below.\n\n\n\nq matrix\n\n\nWe need the log likelihood function for simple calculation. The log likelihood function is constructed by\n\\[\nl(\\underline{x}, \\theta) = \\sum_{i}^{T-1} \\log{Multinomial(N_i, \\underline{q})} = \\sum_{ i= 1}^{T-1} \\sum_{j = 2}^{T}\\text{m-array}[i, j] \\times \\log{\\underline{q}[i, j]}.\n\\]\nWe create a function caplik.constant for the negative log likelihood function, then use optim to find the MLE of our parameters of interest, \\(\\boldsymbol{\\theta}\\). Transfer the estimate of \\(\\boldsymbol{\\theta}\\) back to \\(p\\) and \\(\\phi\\) using plogis. Also, we can obtain standard error for each parameter from inverting the Hessian matrix at the MLE.\nWe can compute the credible interval for each parameter using bootstrap method. Take 50 resamples, find lower and upper quantile for the estimated parameters. The MLE, SD, and 95% credible interval (CI) for estimated parameters are shown below.\n\n\n\n\n\n\nMLE\nSD\nCI\n\n\n\n\n\\(p\\)\n0.539\n0.098\n[0.473,0.592]\n\n\n\\(\\phi\\)\n0.932\n0.093\n[0.903,0.958]"
  },
  {
    "objectID": "posts/2022-08-19_guillemot-survival/index.html#sex-dependent-survival-probabilities",
    "href": "posts/2022-08-19_guillemot-survival/index.html#sex-dependent-survival-probabilities",
    "title": "Investigating the impact of age and sex on guillemot survival",
    "section": "2. Sex dependent survival probabilities",
    "text": "2. Sex dependent survival probabilities\nSince the recapture probability is high (\\(p =\\) 0.539), we do not expect any difference if we model them age or sex dependent. Hence, we would keep \\(p\\) constant in this analysis. Now we are curious about whether the survival probabilities vary with sex. Let \\(\\phi_m\\) and \\(\\phi_f\\) to represent the survival probabilities of male and female. We split the database into 2 separated database according to their sex, and denote them CH.m and CH.f respectively.\nThe likelihood function is slightly different from the constant model, since we have to form two \\(\\underline{q}\\) matrix for both male and female. The log likelihood function becomes\n\\[\nl(\\underline{x};\\theta) = l(\\underline{x_m};\\theta_m) + l(\\underline{x_f};\\theta_f)\n\\]\nwhere\n\\[\nl(\\underline{x_m}, \\theta_m) = \\sum_{i = 1}^{T-1} \\sum_{j = 2}^{T}\\text{m-array}_m[i, j]\\times \\log{\\underline{q_m}[i, j]} \\quad \\text{and}\\\\\nl(\\underline{x_f}, \\theta_f) = \\sum_{i = 1}^{T-1} \\sum_{j = 2}^{T}\\text{m-array}_f[i, j]\\times \\log{\\underline{q_f}[i, j]},\n\\]\nso we also need to construct \\(\\underline{q}\\) for the different sex class. Define function caplik.sex to compute the negative log likelihood for this model.\nThe estimates for \\(p\\) and \\(\\phi\\) depends on sex are shown below.\n\n\n\n\n\n\nMLE\nSD\nCI\n\n\n\n\n\\(p\\)\n0.539\n0.098\n[0.476,0.583]\n\n\n\\(\\phi_m\\)\n0.92\n0.135\n[0.86,0.95]\n\n\n\\(\\phi_f\\)\n0.944\n0.127\n[0.885,0.977]\n\n\n\n\n\nThe difference between \\(\\phi_m\\) and \\(\\phi_f\\) is about 0.02. From the result above, it seems like the sex of an individual does not affect the apparent survival probability."
  },
  {
    "objectID": "posts/2022-08-19_guillemot-survival/index.html#model-with-age-dependent-survival-probabilities",
    "href": "posts/2022-08-19_guillemot-survival/index.html#model-with-age-dependent-survival-probabilities",
    "title": "Investigating the impact of age and sex on guillemot survival",
    "section": "3. Model with Age-dependent survival probabilities",
    "text": "3. Model with Age-dependent survival probabilities\nNext, we want to see if the age of an individual affect the survival probabilities. Usually, young individuals have lower survival probabilities than adults. We denote \\(\\phi_a\\) as the apparent survival probability for individuals at age \\(a\\). We are going to consider different number of age classes:\n\n\\(a = 1, 2, 3+ //\\phi_1, \\phi_2, \\phi_{3+}\\)\n\\(a = 1, 2, 3, 4+ //\\phi_1, \\phi_2, \\phi_3, \\phi_{4+}\\)\n\\(a = 1, 2, 3, 4, 5+ //\\phi_1, \\phi_2, \\phi_3, \\phi_4, \\phi_{5+}\\)\n\nthen we decide which model is the best.\nIn CJS model, in m-array formulation, we will need to construct one m-array for each age class. For instance, for 3 age classes, we will have to construct 3 m-arrays and 3 \\(\\underline{q}\\) matrices accordingly.\nSince the age of individuals changes through years, cell probabilities in \\(\\underline{q}\\) are different from the sex case. The probability of capture history also changes as we have a different \\(\\phi_a\\) for different age \\(a\\).\nUsing the same example as before, for a capture history\n\\[\nx_i = 1 \\quad 1 \\quad 0 \\quad 1 \\quad 1\n\\]\nthe probability of this capture history is now\n\\[\n\\mathbb{P}(x_i) = \\phi_1p\\phi_2(1-p)\\phi_3p\\phi_3p\n\\]\nWhile we have only 3 age classes, \\(\\phi_a\\) beyond the third occasion after the first capture are all \\(\\phi_3\\) instead of \\(\\phi_4, \\phi_5\\) etc.\nNow, for example, when \\(T = 5\\) and if we choose to have 3 age classes, the \\(\\underline{q}\\) for age 1 individuals is like\n\n\n\nq matrix for age 1 individuals (total 3 age classes)\n\n\nSimilar structure will have ages 2, 3, 4 and 5+. For the likelihood function, the construction is the same as before with log likelihood\n\\[\nl(\\underline{x};\\theta) = \\sum_{a}^{A} l(\\underline{x_{a}};\\theta_{a})\n\\] with \\(A = 3, 4, 5\\) representing the number of age class. For example, \\(a = 1, 2, 3, 4\\) for \\(A = 4\\).\nFor our data, we do not have any individuals re-captured on the occasion after the first capture, i.e. we have not seen any 1 year old individual (which is often the case), so we can not estimate \\(\\phi_1\\) and \\(p\\) separately, only its product \\(\\phi_1 p\\). Therefore we let \\(\\phi_1 = 1\\) and \\(p_1 = 0\\) (here \\(p_1\\) means \\(p\\) for occasion 2), the rest of the calculation remains the same. Therefore, \\(\\phi_2\\) can be interpreted as the survival probability until 2 year old. Define functions caplik.age3, caplik.age4 and caplik.age5 for the three models.\nThe estimate for each model is shown below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3 age classes\n\n\n4 age classes\n\n\n5 age classes\n\n\n\n\n\n\n\nMLE\nSD\nCI\nMLE\nSD\nCI\nMLE\nSD\nCI\n\n\n\\(p\\)\n0.705\n0.107\n[0.651,0.768]\n0.752\n0.107\n[0.686,0.801]\n0.71\n0.107\n[0.643,0.803]\n\n\n\\(\\phi_2\\)\n0.636\n0.235\n[0.556,0.742]\n0.592\n0.235\n[0.507,0.67]\n0.605\n0.235\n[0.484,0.677]\n\n\n\\(\\phi_3\\)\n0.981\n0.114\n[0.965,0.992]\n1\n0.252\n[1,1]\n1\n0.252\n[0.998,1]\n\n\n\\(\\phi_4\\)\n-\n-\n-\n0.967\n0.129\n[0.951,0.992]\n0.979\n0.293\n[0.926,1]\n\n\n\\(\\phi_5\\)\n-\n-\n-\n-\n-\n-\n1\n0.143\n[0.941,1]\n\n\n\n\n\nFrom the results we can see that individuals with more than 2 years old have a higher apparent survival probability for all models as we expected.\nWe have done three age-dependent models, now we are going to decide which one is the best model. In this analysis, we are going to use the Akaike Information Criterion (AIC) approach for model-selection. The AIC of a model is defined as\n\\[\nAIC = -2\\log{L(\\underline{x}, \\hat{\\theta})} + 2d\n\\] where \\(d\\) is the number of parameters estimated. The model with the smallest AIC value is preferred.\nCompute the AIC for each model, the result is shown below\n\n\n\n\n\n\nAIC\n\n\n\n\n3 age classes\n635.002\n\n\n4 age classes\n637.002\n\n\n5 age classes\n639.002\n\n\n\n\n\nThe model with 3 age classes has the lowest AIC = 635.002 and therefore it is the best among the three age-dependent models."
  },
  {
    "objectID": "posts/2022-08-19_guillemot-survival/index.html#models-with-survival-probabilities-age-and-sex-dependent",
    "href": "posts/2022-08-19_guillemot-survival/index.html#models-with-survival-probabilities-age-and-sex-dependent",
    "title": "Investigating the impact of age and sex on guillemot survival",
    "section": "4. Models with survival probabilities age and sex dependent",
    "text": "4. Models with survival probabilities age and sex dependent\nWe have already implicated models where survival probabilities were sex-dependent as well as age-dependent. Now we are going to combine them together, which means that survival probabilities we will depend on age and sex, \\(\\phi_{a,s}\\). For example, \\(\\phi_{1,m}\\) represent survival probability for individuals who are male and at age 1. For 3 age classes, we have in total 7 parameters, a constant \\(p\\), and 6 \\(\\phi\\) for both males and females at different age. We will also do 3 models with different numbers of age classes as before.\nThe log likelihood function now becomes\n\\[\nl(\\underline{x};\\theta) = \\sum_{a}^{A} l(\\underline{x_{a,m}};\\theta_{a,m}) + \\sum_{a}^{A} l(\\underline{x_{a,f}};\\theta_{a,f})\\\\\n\\]\nWe use the same approach as before, define three functions caplik.age3.sex, caplik.age4.sex and caplik.age5.sex accordingly, the result for each model shows below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3 age class\n\n\n\n4 age class\n\n\n\n5 age class\n\n\n\n\n\n\n\nsex\nmale\n\nfemale\n\nmale\n\nfemale\n\nmale\n\nfemale\n\n\n\n\nMLE\nSD\nMLE\nSD\nMLE\nSD\nMLE\nSD\nMLE\nSD\nMLE\nSD\n\n\n\\(p\\)\n0.705\n0.107\n0.705\n0.107\n0.691\n0.107\n0.691\n0.107\n0.745\n0.107\n0.745\n0.107\n\n\n\\(\\phi_2\\)\n0.621\n0.327\n0.653\n0.334\n0.632\n0.327\n0.664\n0.334\n0.593\n0.327\n0.625\n0.334\n\n\n\\(\\phi_3\\)\n0.981\n0.171\n0.981\n0.153\n0.981\n0.348\n0.999\n0.364\n0.997\n0.348\n0.998\n0.364\n\n\n\\(\\phi_4\\)\n-\n-\n-\n-\n1\n0.197\n0.99\n0.169\n0.999\n0.416\n0.967\n0.413\n\n\n\\(\\phi_5\\)\n-\n-\n-\n-\n-\n-\n-\n-\n0.957\n0.224\n0.975\n0.186\n\n\n\n\n\nCompute the AIC for each model.\n\n\n\n\n\n\nAIC\n\n\n\n\n3 age classes\n639.195\n\n\n4 age classes\n648.023\n\n\n5 age classes\n624.962\n\n\n\n\n\nFrom the results above, the model with the lowest AIC = 624.962 is the one with 5 age classes. As we can see, there is almost no sex effect on the estimate of survival probabilities in this model. Hence we would like to set some of the \\(\\phi.m\\) and \\(\\phi.f\\) to be the same for some certain age class to see if the model improves."
  },
  {
    "objectID": "posts/2022-08-19_guillemot-survival/index.html#model-selection",
    "href": "posts/2022-08-19_guillemot-survival/index.html#model-selection",
    "title": "Investigating the impact of age and sex on guillemot survival",
    "section": "Model selection",
    "text": "Model selection\nNow we choose 5 models, and assess their performance:\n\nModel 1: all survival probabilities differ for males and females\nModel 2: \\(\\phi_{2.m} = \\phi_{2.f}\\)\nModel 3: \\(\\phi_{2, 3.m} = \\phi_{2, 3.f}\\)\nModel 4: \\(\\phi_{2, 3, 4.m} = \\phi_{2, 3, 4.f}\\)\nModel 5: constant survival probabilities for both males and females\n\nFollowing the same methedology previously explained, we form the likelihood function for each model and then use optim to find the MLE. We then compute the AIC of each model with the following results,\n\n\n\n\n\nModel\nAIC\n\n\n\n\n1. all phi depends on sex\n624.544\n\n\n2. phi2.m = phi2.f\n719.15\n\n\n3. phi2,3.m = phi2,3.f\n625.901\n\n\n4. phi2,3,4.m = phi2,3,4.f\n619.17\n\n\n5. constant phi\n628.78\n\n\n\n\n\nModel 4 gives the lowest AIC = 619.17. So we set \\(\\phi_{2, 3, 4.m} = \\phi_{2, 3, 4.f}\\), and a different survival probabilities for 5 years old males and females, the estimate of the parameters are shown below.\n\n\n\n\n\n\nMLE\nSD\nCI\n\n\n\n\n\\(p\\)\n0.753\n0.107\n[0.665,0.783]\n\n\n\\(\\phi_2\\)\n0.591\n0.235\n[0.49,0.685]\n\n\n\\(\\phi_3\\)\n1\n0.252\n[0.963,1]\n\n\n\\(\\phi_4\\)\n0.984\n0.293\n[0.923,1]\n\n\n\\(\\phi_{5,m}\\)\n0.952\n0.224\n[0.916,1]\n\n\n\\(\\phi_{5,f}\\)\n0.971\n0.186\n[0.923,1]"
  },
  {
    "objectID": "posts/2022-08-19_guillemot-survival/index.html#discussion",
    "href": "posts/2022-08-19_guillemot-survival/index.html#discussion",
    "title": "Investigating the impact of age and sex on guillemot survival",
    "section": "Discussion",
    "text": "Discussion\nIn conclusion, we have implement CJS models to estimate the apparent survival probability and recapture probability. We have built several different models which regard to age and/or sex of the individuals, and we have used AIC method for model selection. The best model (in terms of AIC) was that with constant recapture probability, common sex-survival probabilities for ages 2 to 4, and different sex-survival probabilities for age 5+.\nGuillemot are long live sea birds that in some cases they can live about 40 years. Although both sexes take care of the chick, the energy spent in breeding differs between sexes. This fact may affect the survival probabilities, mainly at older ages. The results are in line with this, showing a common survival probabilities for both sexes until 4 years old (juvenile birds) and being slightly different for breeders (5+).\nHowever, we can see that the difference in the survival probability for males and females are very small. Also, we have higher \\(\\phi_3\\) and \\(\\phi_4\\) than \\(\\phi_5\\). This may not be the case for the whole population. Further analyses are needed to see if there are other factors affecting there results.\nIn this project we only discuss the effects of sex and age on survival probabilities, but there are many other associated factors that can affect the survival probabilities, which are also worth investigating. In addition, due to the long life expectancy, more age classes can be added to see how survival probabilities differ by age.\nFinally, it is worth to note that the estimated parameters are higher than the expected. This may be because of how the data is collected. For our special case, this lab has a globally unique research platform with an artificial rock shelf with enough space to host hundreds of breeding birds. The base of this platform rests in the middle of an established Common Guillemot colony, so instead of staring with binoculars or telescope in thousand meters away, scientists can study the birds from a distance of bare centimeters. This makes sure the data has high precision (recapture probability is almost 1).\nThis report only shows the result of this database, which does not represent the estimation for the entire population."
  },
  {
    "objectID": "posts/2022-08-19_guillemot-survival/index.html#reference",
    "href": "posts/2022-08-19_guillemot-survival/index.html#reference",
    "title": "Investigating the impact of age and sex on guillemot survival",
    "section": "Reference",
    "text": "Reference\nSeber, G. A. F. and Schofield, M. R. (2019). Capture-Recapture: Parameter Estimation for Open Animal Populations. Springer.\nKing, R. (2014). Statistical Ecology. The Annual Review of Statistics and Its Application, 1:401–426.\nMcCrea, R. and Morgan, B. J. T. (2015). Analysis of Capture-recapture Data. CRC Press.\nBalticseabird.com. (2022). Stora Karlsö Auk Lab – BSP. [online] Available at: http://www.balticseabird.com/auk-lab/ [Accessed 29 August 2022]."
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "MIT License",
    "section": "",
    "text": "MIT License\nCopyright (c) 2024 Ashlynn Lu\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "posts/2023-04-11_boundary-layer/index.html",
    "href": "posts/2023-04-11_boundary-layer/index.html",
    "title": "the Boundary Layer Developing when a Uniform Flow Impinges on a Half-Plane",
    "section": "",
    "text": "Analysing the boundary layer developing when a uniform flow impinges on a half-plane by approximating the Navier-Stokes equation and divergence-free conditions, and derived a system of equations that can be solved numerically to obtain the velocity components in the boundary layer.\nWe consider that the boundary layer is formed by a time-independent uniform flow over a half-plane. We assume a uniform flow \\(\\boldsymbol{u}=(\\mathrm{U}, 0,0)\\) as \\(|\\boldsymbol{x}| \\rightarrow \\infty\\) and independence on \\(y\\). The flow impinges on a thin semi-infinite plate at \\(z=0\\) with \\(x&gt;0\\).\nWe approximated the Navier-Stokes equation and divergence-free conditions by \\[\nu \\partial_x u+w \\partial_z u=\\partial_{z z} u, \\quad \\partial_x u+\\partial_z w=0,\n\\] where we use scaled (non-dimensional) variables. We showed that the solution for \\(x&gt;0\\) and \\(z&gt;0\\) can be found in the form \\[\nu=f^{\\prime}(\\eta), \\quad w=\\frac{1}{2 x^{1 / 2}}\\left(\\eta f^{\\prime}(\\eta)-f(\\eta)\\right), \\quad \\text { with } \\quad \\eta=\\frac{z}{x^{1/2}},\n\\] where the function \\(f(\\eta)\\) satisfies the boundary-value problem \\[\nf^{\\prime \\prime \\prime}+\\frac{1}{2} f f^{\\prime \\prime}=0, \\quad \\text { with } \\quad f(0)=f^{\\prime}(0)=0 \\quad \\text { and } \\quad \\lim_{\\eta \\rightarrow \\infty} f^{\\prime}(\\eta)=1.\n\\]\nNote that the \\(z\\) length scale is much shorter than the \\(x\\) length scale, reflecting the thinness of the boundary layer."
  },
  {
    "objectID": "posts/2023-04-11_boundary-layer/index.html#solutions-ux-z-and-wx-z",
    "href": "posts/2023-04-11_boundary-layer/index.html#solutions-ux-z-and-wx-z",
    "title": "the Boundary Layer Developing when a Uniform Flow Impinges on a Half-Plane",
    "section": "Solutions \\(u(x, z)\\) and \\(w(x, z)\\)",
    "text": "Solutions \\(u(x, z)\\) and \\(w(x, z)\\)\nWe are going to investigate the behaviour of the solutions \\(u(x, z)\\) and \\(v(x, z)\\), where \\(u\\) represents the velocity component in the direction of the flow, and \\(w\\) represents the velocity component normal to the flow direction. In order to solve for \\(u\\) and \\(w\\), we need to first express the third-order ordinary differential equation (ODE) as a system of first-order ODEs to find a numerical solution for \\(f(\\eta)\\), \\(f'(\\eta)\\) and \\(f''(\\eta)\\). We define \\(f_1(\\eta)=f(\\eta)\\), \\(f_2(\\eta)=f'(\\eta)\\), and \\(f_3(\\eta)=f''(\\eta)\\). Then, the system becomes \\[\nf_1^{\\prime} =f_2, \\quad\nf_2^{\\prime} =f_3, \\quad\n\\text{and} \\quad f_3^{\\prime} =-\\frac{1}{2} f_1 f_3 ,\n\\] with the initial conditions \\[\nf_1(0) = f(0) = 0, \\quad\nf_2(0) = f^{\\prime}(0) = 0, \\quad\n\\text{and} \\quad \\lim_{\\eta \\rightarrow \\infty} f_2(\\eta) = \\lim_{\\eta \\rightarrow \\infty} f^{\\prime}(\\eta) = 1.\n\\]\n\n\n\nThe solutions \\(u(x, z)\\) and \\(w(x, z)\\) represent the velocity components of the fluid flow in the boundary layer. The colorbars show the range of values of the velocity components.\n\n\nWe can observe that the velocity profile is characterised by a thin boundary layer close to the wall, where the velocity increases rapidly from zero at the wall to its maximum value at the edge of the boundary layer. Beyond the boundary layer, the velocity approaches the free stream value, which is constant across the entire flow domain.\nThe flow is assumed to be uniform in the \\(x\\) direction far from the plate, so \\(u\\) becomes constant and equal to the free-stream velocity \\(\\mathrm{U}\\). Near the plate at \\(z=0\\), the velocity component \\(w\\) is zero due to the no-slip condition. As we move away from the plate in the \\(z\\) direction, the velocity component \\(w\\) increases due to the viscous effects of the fluid."
  },
  {
    "objectID": "posts/2023-04-11_boundary-layer/index.html#the-boundary-layer-thickness",
    "href": "posts/2023-04-11_boundary-layer/index.html#the-boundary-layer-thickness",
    "title": "the Boundary Layer Developing when a Uniform Flow Impinges on a Half-Plane",
    "section": "The boundary layer thickness",
    "text": "The boundary layer thickness\nThe (non-dimensional) boundary layer thickness can be defined as \\[\n\\delta(x)=\\int_0^{\\infty}(1-u(x, z)) \\mathrm{d} z.\n\\]\nUsing the expression for \\(u(x,z)\\) from (\\(\\ref{solution_uw}\\)) and using the change of variable \\(\\eta = z/x^{1/2}\\), we have \\[\n\\begin{align*}\n\\delta(x) &=  \\int_0^{\\infty} \\left(1-f'(\\eta)\\right) x^{1/2} \\mathrm{d}\\eta \\\\\n&= \\lim_{L\\to\\infty} x^{1/2} \\int_0^{L} \\left(1-f'(\\eta)\\right) \\mathrm{d}\\eta \\\\\n&= \\lim_{L\\to\\infty} x^{1/2} \\left[\\eta-f(\\eta)\\right]_0^{L} \\\\\n&= \\lim_{L\\to\\infty} x^{1/2} \\left(L - f(L)\\right),\n\\end{align*}\n\\] where we use that \\(f(0) = 0\\).\nWe can estimate this by taking a finite but large \\(L\\) such as \\(L = 10\\). Therefore we get an estimate for \\(\\delta(x)\\) which is \\[\n\\delta(x) \\approx x^{1/2}(10 - f(10)) = x^{1/2}(10 - 8.28) = 1.72x^{1/2}.\n\\] It shows that the boundary layer thickness increases with the distance from the wall. When the distance from the wall is very small, the thickness of the boundary layer becomes negligible.\nThe formula for the (non-dimensional) viscous stress at the wall can be defined as \\[\n\\sigma(x)=\\left.\\partial_z u(x, z)\\right|_{z=0}.\n\\]\nUsing the expression for $ u(x, z)=f’()$ and \\(\\eta = z/x^{1/2}\\) from (\\(\\ref{solution_uw}\\)), we can obtain the derivative with respect to \\(z\\) as \\[\n\\frac{\\partial u(x, z)}{\\partial z}=\\frac{d}{d \\eta} f^{\\prime}(\\eta) \\cdot \\frac{\\partial \\eta}{\\partial z}=\\frac{1}{x^{1 / 2}} f^{\\prime \\prime}(\\eta).\n\\] Evaluating this at \\(z=0\\) gives \\[\n\\sigma(x)=\\left.\\partial_z u(x, z)\\right|_{z=0}=\\frac{1}{x^{1 / 2}} f^{\\prime \\prime}(0).\n\\]\nSince we have numerically computed \\(f''(\\eta)\\) for \\(\\eta \\in (0, 10)\\), we obtain a numeric estimate \\(f''(0) = 0.332\\). Therefore we have \\[\n\\sigma(x)=\\frac{0.332}{x^{1 / 2}}.\n\\] This tells us that the viscous stress at the wall decreases as the distance from the wall increases, and it becomes very small for large values of \\(x\\). This is consistent with the idea that the flow far away from the wall is nearly inviscid, and that the viscous effects are confined to a thin layer near the wall, as described by the boundary layer theory."
  },
  {
    "objectID": "posts/2023-04-11_boundary-layer/index.html#discussion",
    "href": "posts/2023-04-11_boundary-layer/index.html#discussion",
    "title": "the Boundary Layer Developing when a Uniform Flow Impinges on a Half-Plane",
    "section": "Discussion",
    "text": "Discussion\nThe numerical estimate for the boundary layer thickness, \\(\\delta\\), shows that the boundary layer grows as the distance from the wall increases, which means that the velocity gradient near the wall decreases, and the flow becomes more uniform in the outer region. For the viscous stress at the wall, \\(\\sigma\\), the estimate illustrates that the stress decreases with increasing distance from the wall, indicating that the flow is less influenced by the wall friction further away from the wall.\nHowever, it is important to keep in mind that these estimates are based on a simplified model, so they may not capture all the details and complexities of the actual flow. Furthermore, the accuracy of the estimates may depend on the choice of the domain size and the numerical method used to solve the boundary value problem. Therefore, it is important to validate these estimates against experimental or to refine the numerical methods and models used."
  },
  {
    "objectID": "posts/2024-02-02_breast-cancer/index.html",
    "href": "posts/2024-02-02_breast-cancer/index.html",
    "title": "Classification of the Breast Cancer Wisconsin Data Set",
    "section": "",
    "text": "In this article, we explore into the Breast Cancer Wisconsin Data Set, a comprehensive compilation of 30 features from 569 breast masses, aimed at distinguishing malignant from benign cases using advanced classification techniques.\nWe will use three classifiers to classify whether a breast mass is malignant or benign: a logistic regression, a k-nearest neighbours classifier (KNN), and a Naive Bayes classifier."
  },
  {
    "objectID": "posts/2024-02-02_breast-cancer/index.html#exploratory-data-analysis",
    "href": "posts/2024-02-02_breast-cancer/index.html#exploratory-data-analysis",
    "title": "Classification of the Breast Cancer Wisconsin Data Set",
    "section": "Exploratory Data Analysis",
    "text": "Exploratory Data Analysis\n\n\n\nA plot of histograms showing the distribution of the observations of each of the 30 covariates for both categories (blue for malignant (M) and orange for benign (B)).\n\n\nThe distribution plot shows that most of the mean values of the features are approximately normally distributed, while some of the variables, especially the standard error terms (denoted in the pattern `feature se’) have skewed distribution. We can also inspect that some of the covariates have significantly different distributions for the different diagnosis results, such as mean radius, mean perimeter, mean area, mean compactness, mean concavity, and mean concave points.\nWe should also briefly examine the correlation between the features to do the classification using naive Bayes classifier since it assumes conditional independence. Intuitively, we may think that perimeter and area should be highly correlated with the radius of the breast masses. The heatmap below agrees with our opinion.\n\n\n\nA heatmap showing the correlation between features."
  },
  {
    "objectID": "posts/2024-02-02_breast-cancer/index.html#classification",
    "href": "posts/2024-02-02_breast-cancer/index.html#classification",
    "title": "Classification of the Breast Cancer Wisconsin Data Set",
    "section": "Classification",
    "text": "Classification\nNow we can so the classification. All three classifiers needs different model assumptions. The logistic Regression classifier assumes a linear relationship between the features and the log-odds of the target variable, while KNN assumes that instances of the same class are locally clustered in the feature space (local smoothness). Naive Bayes assumes that features are conditionally independent given the class label. Note that this is a strong assumption and may not hold in all real-world scenarios. In addition, we spot that the dataset contains features like radius, area, and perimeters, which are highly correlated. Therefore the Naive Bayes may not perform well on this dataset.\nTo compare the performance of three classifiers and assess their stability across different training/test set divisions, we use cross-validation, which involves splitting the dataset into multiple subsets and training the models on different combinations of these subsets. We use a k-fold cross-validation (we use the small letter k to differentiate from the \\(K\\) in KNN). We choose to split the dataset into 5 approximately equal-sized folds. The dataset is shuffled before splitting into folds to ensure randomness and avoid any potential ordering effects in the data. Then we iterate through each of the k folds. For each iteration, one fold is used as the test set, and we train the models using the remaining k-1 folds (training set). We compute the accuracy score for each iteration, and average the accuracy score from all k iterations to obtain a single mean accuracy score.\nThese procedures are done by using package sklearn. We use StratifiedKFold for the cross-validation, LogisticRegression, KNeighborsClassifier, GaussianNB for the classification model, and cross_val_score to assess the accuracy and stability. We choose \\(K=3\\), \\(K=5\\), and \\(K=7\\) for the numbers of neighbours for the k-nearest neighbours classifier.\n\n\n\nThe mean accuracy score and standard deviation for the three classifiers, Logistic regression, KNN (for the number of neighbours = 3, 5, 7), and Naive Bayes.\n\n\nThe table above shows the performance of each classifier. We can see that the accuracy is all greater than 0.90 with a small standard deviation around 0.015, which shows that the three classifiers are accurate. Also, for the KNN classifier, the result shows that the mean accuracy is the largest when \\(K=3\\).\nWe repeat the entire k-fold cross-validation process 10 times across different random training/test set divisions for stability assessment. The figure below shows that the performance of all the classifiers is stable across different training/test set divisions, with the logistic regression classifier having the highest accuracy, and Naive Bayes having the lowest accuracy across all 10 iterations. The lower accuracy for the Naive Bayes may be because of the correlated features in the dataset. We can see that the performances of all three KNN classifiers are similar. We will choose \\(K=3\\) for further analysis when using KNN.\n\n\n\nA plot showing the accuracy for the three classifiers for 10 different training/test set divisions."
  },
  {
    "objectID": "posts/2024-02-02_breast-cancer/index.html#cost",
    "href": "posts/2024-02-02_breast-cancer/index.html#cost",
    "title": "Classification of the Breast Cancer Wisconsin Data Set",
    "section": "Cost",
    "text": "Cost\nSuppose that wrongly classifying a breast mass as benign (false negative) has a cost of 100 while wrongly classifying a breast mass as malignant (false positive) has a cost of 5. We divide the dataset into 20-80 train-test sets, train the three models on the training set, and compute the classification costs using the test set. For each classifier, we plot the classification cost on a test set associated with different decision thresholds (from 0 to 1). Choosing a high threshold typically results in a higher precision (fewer false positives) but a lower recall (more false negatives) because the model is more selective in labeling instances as positive.\n\n\n\nA plot showing the classification cost on a test set associated with different decision thresholds\n\n\nWe can see that the classification costs for the three methods are slightly increasing for increasing thresholds. The costs are approximately lower than 600 for the KNN and Naive Bayes classifiers for all possible threshold values. The cost for logistic regression is the lowest among the three classifiers when the threshold is smaller than 0.8, but the cost increases rapidly when the threshold is larger than 0.8.\nIf we want to minimise the overall cost, we need to balance false positives and false negatives. In this scenario, we would like to set a lower threshold to minimise the cost associated with false negatives (malignant cases misclassified as benign). Logistic Regression models output probabilities, and you can adjust the threshold to control the trade-off between false positives and false negatives. I would recommend using the logistic regression with a threshold lower than 0.8, since it minimises the classification cost."
  },
  {
    "objectID": "posts/2023-03-17_Q-Q-plot/index.html",
    "href": "posts/2023-03-17_Q-Q-plot/index.html",
    "title": "Interactive Q-Q Plot",
    "section": "",
    "text": "Data visualization plays a significant role in data analysis. It is a process of transforming large amounts of complex numerical data into more manageable visual representations, hence helping statisticians to discover and identify any unexpected pattern of data.\nThe objective when performing a formal hypothesis test is to propose and calculate a numerical test statistic and compare it to some critical value under the null hypothesis to make a binary decision, either to reject or fail to reject the null hypothesis. Similarly, the objective when creating a data visualisation is to describe the data and to make some decisions about it. Graphical procedures, such as the quantile–quantile (Q–Q) plot, are undoubtedly the most popular methods to identify the nature of the distribution of data."
  },
  {
    "objectID": "posts/2023-03-17_Q-Q-plot/index.html#assessment-of-normality",
    "href": "posts/2023-03-17_Q-Q-plot/index.html#assessment-of-normality",
    "title": "Interactive Q-Q Plot",
    "section": "Assessment of Normality",
    "text": "Assessment of Normality\nAn assessment of the normality of data is necessary for checking the validation of assumptions in various parametric statistical tests, including linear regression, t-tests, and analysis of variance. If this assumption is violated then the conclusion of these tests will be unreliable. There are two main methods of assessing normality: graphical and numerical. In this study, we mainly focus on the Q-Q plot for the graphical method, together with the Shapiro–Wilk test for the numerical test.\n\nQuantile-Quantile Plots (Q-Q Plots)\nA Q-Q plot is a probability plot which compares if two probability distributions are close to each other by shape by plotting their quantiles against each other. If the two distribution is similar, the points on the plots are approximately allocated on the identity line \\(y = x\\). Q-Q plots are frequently utilized to compare a sample’s distribution to that of the standard normal distribution \\(N(0,1)\\). This is done by sorting the data and plotting them against specific quantiles of the standard normal distribution. Unlike numerical tests like the Shapiro–Wilk test which only indicates normality but without any feature of the distribution, properties of shapes of distribution such as heavy-tail, light-tail, and skewness are identifiable in Q-Q plots."
  },
  {
    "objectID": "posts/2023-03-17_Q-Q-plot/index.html#numerical-test",
    "href": "posts/2023-03-17_Q-Q-plot/index.html#numerical-test",
    "title": "Interactive Q-Q Plot",
    "section": "Numerical Test",
    "text": "Numerical Test\nOne well-known statistical tests for normality is the Shapiro–Wilk (SW) test. In the SW test, the null hypothesis is that the sample, \\(x_1, \\cdots , x_n\\), was drawn from a population that follows a normal distribution. If the p-value of the test is below a specific significance level, such as \\(\\alpha = 0.05\\), then there is enough evidence to reject the null hypothesis, indicating that the data does not follow a normal distribution. We are going to discuss the different configurations of the two tests.\nHowever, the numerical test will sometimes give misleading results. Below shows a Q-Q plot using a sample with size \\(n = 30\\) of data generated from the standard normal distribution.\n\n\n\n\n\n\n\n\n\nThe p-value for SW test is:  0.033\n\n\nWe can see that even though the data are generated from the standard normal distribution, the SW test suggests a rejection towards normality because of the tail behaviour. Therefore, the numerical tests should always be interpreted along with a graphical method, i.e. a Q-Q plot."
  },
  {
    "objectID": "posts/2023-03-17_Q-Q-plot/index.html#confidence-interval",
    "href": "posts/2023-03-17_Q-Q-plot/index.html#confidence-interval",
    "title": "Interactive Q-Q Plot",
    "section": "Confidence Interval",
    "text": "Confidence Interval\nWhen we inspect a Q-Q plot, we say the data is similar to a normal distribution if the empirical and theoretical quantiles roughly coincide with the line denoting the theoretical distribution. Then the question is: how close the points and line should be considered as ‘lie on the line’?\nSimilar to how we may conclude a typical hypothesis test by assessing if the test statistic exceeds the corresponding critical value, we may consider adding a point-wise confidence interval here to assist the decision of normality by examining whether the data points lie within or exceed the interval bands. The construction of the confidence band is by repeated sampling. A 95% confidence band for the Q-Q plots represents a range of values that we may expect each quantile to be under the assumption of repeated sampling of the standard normal distribution. In this report, we are generating a large number of random samples (number of samples = 1000) of size equal to our data (n = 30) from the standard normal distribution, obtaining the 2.5% and the 97.5% quantiles for each point, and forming a confidence interval for each point estimate.\n\n\n\n\n\n\n\n\n\nFor this example, we may say that we fail to reject normality as all points fall inside of the bands."
  },
  {
    "objectID": "posts/2023-03-17_Q-Q-plot/index.html#try-to-identify-normality-of-the-data",
    "href": "posts/2023-03-17_Q-Q-plot/index.html#try-to-identify-normality-of-the-data",
    "title": "Interactive Q-Q Plot",
    "section": "Try to identify normality of the data!",
    "text": "Try to identify normality of the data!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Hi there!",
    "section": "",
    "text": "My name is Kexin Lu, you can call me Ashlynn.\nI am a MSc statistic student at Imperial College London."
  },
  {
    "objectID": "index.html#interest",
    "href": "index.html#interest",
    "title": "Hi there!",
    "section": "Interest",
    "text": "Interest\nMy research interests are in the field of data science and AI."
  },
  {
    "objectID": "index.html#hobby",
    "href": "index.html#hobby",
    "title": "Hi there!",
    "section": "Hobby",
    "text": "Hobby\nI like gaming 🎮, playing guitar 🎸, photography 📷. You can find some of my photos here."
  },
  {
    "objectID": "writing.html",
    "href": "writing.html",
    "title": "Research",
    "section": "",
    "text": "Colorado Legal Cannabis Sales Report\n\n\n\n\n\n\ndata visualisation\n\n\narticle\n\n\n\n\n\n\n\n\n\nFeb 21, 2024\n\n\nAshlynn Lu\n\n\n\n\n\n\n\n\n\n\n\n\nClassification of the Breast Cancer Wisconsin Data Set\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 2, 2024\n\n\nAshlynn Lu\n\n\n\n\n\n\n\n\n\n\n\n\nthe Boundary Layer Developing when a Uniform Flow Impinges on a Half-Plane\n\n\n\n\n\n\nanalysis\n\n\nfluid mechanics\n\n\n\n\n\n\n\n\n\nApr 11, 2023\n\n\nAshlynn Lu\n\n\n\n\n\n\n\n\n\n\n\n\nSubjective Interpretation of Statistical Information via the Use of Q-Q plot\n\n\n\n\n\n\ndata visualisation\n\n\ninteractive plots\n\n\n\n\n\n\n\n\n\nMar 17, 2023\n\n\nAshlynn Lu\n\n\n\n\n\n\n\n\n\n\n\n\nComplex Analysis Method for Potential Flows and the Resulting Lift\n\n\n\n\n\n\nanalysis\n\n\nfluid mechanics\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\nAshlynn Lu\n\n\n\n\n\n\n\n\n\n\n\n\nInvestigating the impact of age and sex on guillemot survival\n\n\n\n\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nAug 19, 2022\n\n\nAshlynn Lu\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  }
]